{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35Ya3-zS_Lms"
   },
   "source": [
    "# Brain Tumor Binary Classifier (2D MRI)\n",
    "\n",
    "This notebook presents a deep learning pipeline for classifying 2D brain MRI scans into two categories: **Tumor** and **No Tumor**.\n",
    "\n",
    "The model is built using **PyTorch** and employs a simple convolutional neural network (CNN) architecture tailored for binary classification. Augmentations and preprocessing are applied using **Albumentations**, and the data pipeline leverages **Hugging Face Datasets** for streamlined loading.\n",
    "\n",
    "The dataset used was originally published on [Kaggle](#) and is re-hosted on the **Hugging Face Hub** with minor modifications to support binary classification.\n",
    "\n",
    "This project is part of a personal initiative to explore medical imaging with computer vision, focusing on **data preprocessing**, **augmentation techniques**, and **model generalization** in a simplified binary classification task.\n",
    "\n",
    "> **Disclaimer:** This project is for **educational and research purposes only**. It is *not* intended for medical or clinical use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiO43mAFhVLv"
   },
   "source": [
    "## 1. Setup & Dependencies\n",
    "\n",
    "This section installs and imports the required libraries for data handling, model development, training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8a-WBDfv_xIT"
   },
   "source": [
    "### 1.1 Install Dependencies (Colab Only)\n",
    "\n",
    "If you're using Google Colab, install the required packages using the command below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 4445,
     "status": "ok",
     "timestamp": 1751204871311,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "lBiHHo4akI1y",
    "outputId": "89319b6a-fe64-4f3a-93a4-dd8338dcfbb9"
   },
   "outputs": [],
   "source": [
    "#install dataset from Huggingface\n",
    "!pip install -U datasets fsspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYYpPuOx_2R9"
   },
   "source": [
    "### 1.2 Import Libraries\n",
    "\n",
    "We import all necessary libraries including PyTorch, Albumentations, scikit-learn, and Hugging Face datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHmDFM2whpVE"
   },
   "outputs": [],
   "source": [
    "# PyTorch core modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Torchvision for model architectures and data utilities\n",
    "from torchvision import datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# Albumentations for data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Hugging Face datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Zi7Z6zjrYK"
   },
   "source": [
    "## 2. Load and Prepare Raw Dataset\n",
    "\n",
    "We load a binary brain MRI dataset from the Hugging Face Hub using the `load_dataset` function. This dataset contains two categories and was originally sourced from Kaggle. It is automatically cached for reuse.\n",
    "\n",
    "The loaded data will be split into training and validation sets using a **stratified sampling** strategy to ensure balanced class representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0l0mRXfAc-s"
   },
   "source": [
    "### 2.1 Load Dataset from Hugging Face\n",
    "\n",
    "We load the dataset directly using the `datasets` library. The dataset contains labeled 2D brain MRI scans across two classes: **tumor** and **no tumor**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "cec3d0440a174b299dd676a4eab1b4b6",
      "e7e3782518d84caebcacf100726b5d91",
      "754a80779d114e6bb80cb870bc7aa91f",
      "aa740e5d021e47ac979f0e8eb8438e2b",
      "7741318a27c94f2a80ac6fdd58f81e0f",
      "eea1519298a542f48adb466018e52f5f",
      "b892501ac43040e3abdaf68da535da2f",
      "f1de1879e6d9451eaed90c6407fc8695",
      "109dfc3426464ddbba4fe1a6921fb606",
      "e935be90f99e46b180a30143b86f8b54",
      "8aa8f0502390401ba1cbae88cf943f1e",
      "89464ff1517a4e809c9d466f27dbfc49",
      "7a2f740e18754dce9dcacc9fb56c1d8e",
      "1c3554307df14e5185dc2a7aaadca8f7",
      "49935354f63a4a61a9871ad351fa71dd",
      "bc2e10aa56c24f94b3c17e19938ea8c9",
      "98eead876ae249e7bfc7a178f6505a1d",
      "bf2bae97df7d454d838b998819841d94",
      "a4d150d25b7c4831a5ea392aebe95579",
      "0fb52158b865408ab243e23509fdf24e",
      "3c553af40d41493ebcc8154f66eefd20",
      "842c575302fe4f0bb50f5fb43611f9df",
      "d3c271022b694856aaf6ba729fe84dda",
      "df45b80359f94fb2ae9c3f5a9680cbbf",
      "4cd5dcd133534f63aa95f2781b2dae24",
      "dff7c8e798cb4678a3a4bed983580a9f",
      "d49618e2b04042a19bd172d0eef3d40e",
      "4e5330d7b42a4ff88a7ea01946830ba7",
      "310b205ecd954166becc9663afab8b0a",
      "1b31b772a5194c7ca29764a4959ab73f",
      "5740e0e226f0410dbc87dca25cab66ad",
      "fcfe32f0165c4d0c91cb7a27edf95bd0",
      "9cc76172930e40ee8ffec48f5a33db84",
      "ead82cc76cc641899415b45be8f67378",
      "532adfa536c14ba3a9714b79c1f63590",
      "84b23767c26745368db35f353a75aedc",
      "3a327b1871aa474083681b0dece06993",
      "3f00a05fe538439185309294004c40c0",
      "0f39a35e75504a3f8729c3df3600f1d3",
      "0dcf4728c88d484aabb957f024743921",
      "e9c282dd87e14271aa16490ebcfaa1d0",
      "1e7df20e22ec4de7a2f12d822959cb7e",
      "7074a559ac8041e4b9bcbf27b0ee100a",
      "2bda3fc3941c42e1b412043d91116bcb",
      "f75ea63aa1f24d67b9f6f7e5be34bbb6",
      "103b301e828141de858c05ca9c71344e",
      "987a9740d2b9461ca98017272a05e5fc",
      "bd8051b2737244dca8b415592ab9f1a2",
      "28f946cadefa4cd7b76a31931e0787c0",
      "f12edd801f6844c994265f6a7ae21be3",
      "4e76e3deee4b48a5869c608fd917e3b4",
      "c1be96ebd1b1457eb3c246d55ae96cd8",
      "139eb771d44f4c27abc5859f2bccdcbc",
      "6b6cab0122334b35891787e3b4065506",
      "55cab8058dec4b4eb4bab48100cdf0f9"
     ]
    },
    "executionInfo": {
     "elapsed": 11285,
     "status": "ok",
     "timestamp": 1751204882607,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "vHuN7YXKju4Q",
    "outputId": "08a83dfb-cbab-488a-8ec3-ca97d6a210d1"
   },
   "outputs": [],
   "source": [
    "# Load brain tumor dataset from Hugging Face (auto-cached locally)\n",
    "ds = load_dataset(\"Cayanaaa/BrainTumorDatasets\", name=\"binary\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs5LUD37CO3s"
   },
   "source": [
    "### 2.2 View Class Label Mapping\n",
    "\n",
    "This command reveals the label names and their corresponding integer encodings used internally by the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LhqbHq6CCvv"
   },
   "outputs": [],
   "source": [
    "# Display class labels and their corresponding integer indices\n",
    "print(ds['train'].features['label'].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZN4x5RWFko9a"
   },
   "source": [
    "### 2.3 Extract Images and Labels from Dataset\n",
    "\n",
    "We extract the raw image and label pairs from the dataset for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0t2Hz_vBnJMy"
   },
   "outputs": [],
   "source": [
    "# Split Data\n",
    "train_data = ds['train']\n",
    "images = train_data['image']\n",
    "labels = train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yr8K2FfVCZR0"
   },
   "source": [
    "### 2.4 Stratified Train-Validation Split\n",
    "\n",
    "To ensure balanced class distribution across the training and validation sets, we perform a stratified split. This minimizes the risk of class imbalance during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7lSoQcxfCaGB"
   },
   "outputs": [],
   "source": [
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  stratify=labels,\n",
    "                                                                  random_state=42\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_j-ue-OvtQt"
   },
   "source": [
    "## 3. Dataset Preparation\n",
    "\n",
    "In this section, we prepare the image dataset by applying preprocessing and augmentation techniques, defining a custom PyTorch `Dataset` class, and creating `DataLoaders` for both training and validation phases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfoXl9jLCmNQ"
   },
   "source": [
    "### 3.1 Define Transformation Pipelines\n",
    "\n",
    "We define image preprocessing and augmentation pipelines using **Albumentations** to improve generalization and performance.\n",
    "\n",
    "- The **training pipeline** includes resizing, flipping, distortion, noise, and normalization.\n",
    "- The **validation pipeline** includes only resizing and normalization to ensure consistent evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBA_97AZk9kl"
   },
   "outputs": [],
   "source": [
    "# Define preprocessing & augmentation for training set\n",
    "train_T = A.Compose([\n",
    "    A.Resize(224, 224), # Resize to model input size\n",
    "    A.HorizontalFlip(p=0.5), # Random horizontal flip\n",
    "    A.VerticalFlip(p=0.5),  # Random vertical flip\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Slight brightness/contrast variation\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.03, p=0.2),  # Grid-based distortion\n",
    "    A.GaussNoise(p=0.1), # Add Gaussian noise\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], # Normalize using ImageNet stats\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2() # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Define preprocessing for validation set (no augmentation)\n",
    "val_T = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoPA_w-_vP_2"
   },
   "source": [
    "### 3.2 Define Custom Dataset Class\n",
    "\n",
    "We define a custom PyTorch `Dataset` class to:\n",
    "\n",
    "- Apply the appropriate transformations.\n",
    "- Return each image and its label in tensor format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPUrQ35PwKdg"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to load image-label pairs and apply transforms\n",
    "class LoadDataset(Dataset):\n",
    "  def __init__(self, image_data, labels, transform=None):\n",
    "    self.image_data = image_data\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img = self.image_data[idx]\n",
    "    img = img.convert('RGB') # Ensure image is in RGB format\n",
    "    img = np.array(img)\n",
    "\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.transform:\n",
    "      img = self.transform(image=img)['image']\n",
    "\n",
    "    return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_takYcLC8AU"
   },
   "source": [
    "### 3.3 Create Dataset & DataLoader\n",
    "\n",
    "We wrap the image-label pairs using our custom `Dataset` class, and prepare `DataLoaders` to efficiently feed data during training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtChA0LHj-EQ"
   },
   "outputs": [],
   "source": [
    "# Wrap image and label arrays into Dataset objects\n",
    "train_dataset = LoadDataset(train_imgs, train_labels, train_T)\n",
    "val_dataset = LoadDataset(val_imgs, val_labels, val_T)\n",
    "\n",
    "# Create DataLoaders for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # shuffle for training\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False) # no shuffle for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQ1XXg0Sk_3f"
   },
   "source": [
    "## 4. Model, Optimizer, and Training Setup\n",
    "\n",
    "We adopt a **transfer learning** approach using a pre-trained **DenseNet121** model. To preserve the visual features learned from ImageNet, all convolutional layers are **frozen**, and we train **only the classifier head**. This initial setup focuses on **feature extraction**, before performing full fine-tuning in a later stage.\n",
    "Define Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WffvuN_TDQRY"
   },
   "source": [
    "### 4.1 Load Pre-trained Model\n",
    "\n",
    "We load **DenseNet121** with ImageNet weights to leverage powerful low-level feature extraction learned from large-scale natural images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 524,
     "status": "ok",
     "timestamp": 1751204889671,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "h9CWMsb0l6-M",
    "outputId": "507b69e1-3b85-424c-b72d-092fad2e0be7"
   },
   "outputs": [],
   "source": [
    "# Load DenseNet121 model pre-trained on ImageNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the feature extractor to retain pre-trained representations\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# Replace the classifier head to match the number of output classes (4)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "639U648FoaGX"
   },
   "source": [
    "### 4.2 Define Optimizer, Scheduler, and Device\n",
    "\n",
    "We use the Adam optimizer to update only the classifier head. A learning rate scheduler reduces the learning rate when validation performance plateaus. GPU is used if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1751204889945,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "NfMAbM0Toi33",
    "outputId": "f6eba272-aaf7-4fff-d551-e562a05190b3"
   },
   "outputs": [],
   "source": [
    "# Configure optimizer to update only the classifier head\n",
    "early_optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "# Set up learning rate scheduler to reduce LR if validation loss stops improving\n",
    "scheduler_early =ReduceLROnPlateau(early_optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "# Automatically use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbTLK1l3DkCM"
   },
   "source": [
    "### 4.3 Define Weighted Loss Function\n",
    "\n",
    "To address class imbalance in the training data, we compute class weights and apply them to the cross-entropy loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPZ5RgIHDmv_"
   },
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance and reduce bias toward frequent classes\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define weighted cross-entropy loss\n",
    "crieterion = nn.CrossEntropyLoss(weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1pYvoI7GtY-m"
   },
   "source": [
    "### 4.4 Define Early Stopping\n",
    "\n",
    "We implement a custom early stopping mechanism to terminate training when the validation loss no longer improves after a specified number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-jvHV9Vt-dJ"
   },
   "outputs": [],
   "source": [
    "# Custom early stopping class to monitor validation performance\n",
    "# Stops training if no improvement is observed over 'patience' epochs\n",
    "class EarlyStopping:\n",
    "    def __init__(self, monitor='val_loss', mode='min', patience=3, delta=0.0, verbose=True):\n",
    "         \"\"\"\n",
    "        Args:\n",
    "            monitor (str): Metric to monitor ('val_loss' or 'val_acc')\n",
    "            mode (str): 'min' → lower is better, 'max' → higher is better\n",
    "            patience (int): # of epochs with no improvement before stopping\n",
    "            delta (float): Minimum change to qualify as improvement\n",
    "            verbose (bool): Print status each epoch if True\n",
    "        \"\"\"\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "        # Set comparison function and initial best value\n",
    "        if self.mode == 'min':\n",
    "            self.monitor_op = lambda current, best: current < best - self.delta\n",
    "            self.best_score = np.inf\n",
    "        elif self.mode == 'max':\n",
    "            self.monitor_op = lambda current, best: current > best + self.delta\n",
    "            self.best_score = -np.inf\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'min' or 'max'\")\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        # Initialize best score\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] Initial best {self.monitor}: {self.best_score:.4f}\")\n",
    "        # Check for improvement\n",
    "        elif self.monitor_op(current_score, self.best_score):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] Improved {self.monitor}: {self.best_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] No improvement in {self.monitor} for {self.counter}/{self.patience} epochs.\")\n",
    "            # Stop training if performance has not improved for 'patience' epochs\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"[EarlyStopping] Stopping training. Best {self.monitor}: {self.best_score:.4f}\")\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JemPUYahuFZu"
   },
   "outputs": [],
   "source": [
    "# Create an EarlyStopping instance to monitor validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rIIFJsYua1U"
   },
   "source": [
    "## 5. Train Classifier Head (Warm-up Phase)\n",
    "\n",
    "In this phase, we only train the classifier head (fully connected layers) while keeping the backbone frozen. This **warm-up strategy** helps the model gradually adapt to the domain-specific brain MRI data without modifying the general features learned from ImageNet.\n",
    "\n",
    "The goal is to allow the final layers to specialize on our dataset before unfreezing and fine-tuning the entire network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 629145,
     "status": "ok",
     "timestamp": 1751205519092,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "MWGINZymudFm",
    "outputId": "049ba659-8c4a-4453-a56d-63caab319a60"
   },
   "outputs": [],
   "source": [
    "# Save initial model weights and set best validation loss to infinity\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_loss = np.inf\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  print(f\"-\" * 50)\n",
    "  print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "  print(f\"-\" * 50)\n",
    "\n",
    "  # --- Training Phase ---\n",
    "  model.train()\n",
    "  train_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    early_optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = crieterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    early_optimizer.step()\n",
    "\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "  avg_train_loss = train_loss / total\n",
    "  train_acc = correct / total\n",
    "\n",
    "  # --- Validation Phase ---\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = crieterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item() * images.size(0)\n",
    "      _, predicted = torch.max(outputs, dim=1)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    # ==== output per epoch ====\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Step the learning rate scheduler and update early stopping\n",
    "    scheduler_early.step(avg_val_loss)\n",
    "    early_stopping(avg_val_loss)\n",
    "\n",
    "    # Save model weights if validation loss improves\n",
    "    if avg_val_loss < best_val_loss:\n",
    "      best_val_loss = avg_val_loss\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      torch.save(model.state_dict(), 'best_model.pth')\n",
    "      print(f\"[INFO]: Best Model Updated\")\n",
    "\n",
    "    # Stop training if early stopping is triggered\n",
    "    if early_stopping.early_stop:\n",
    "      print(f\"[INFO]: Training stopped by early stopping\")\n",
    "      break\n",
    "\n",
    "# Load best model weights after training\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(f\"[INFO]: Best model loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pho1J2I465OM"
   },
   "source": [
    "## 6. Fine-Tuning Setup\n",
    "\n",
    "In this phase, we fine-tune the deeper parts of the model to better adapt to the brain tumor classification task. Instead of unfreezing the entire backbone, we selectively unfreeze the final convolutional block and normalization layer to balance adaptability and generalization.\n",
    "\n",
    "Fine-tuning allows the model to refine high-level features learned from ImageNet in a domain-specific context.\n",
    "\n",
    "Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLbcRAwFFL8d"
   },
   "source": [
    "### 6.1 Unfreeze Selected Layers\n",
    "\n",
    "Here, we unfreeze the `denseblock4` and `norm5` layers of the backbone while keeping all earlier layers frozen. This selective unfreezing helps avoid overfitting and reduces the risk of catastrophic forgetting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K36Qs3va6_yM"
   },
   "outputs": [],
   "source": [
    "# Only unfreeze the last DenseBlock and final batch norm layer (norm5)\n",
    "for name, layer in model.named_parameters():\n",
    "  if 'denseblock4' in name or 'norm5' in name:\n",
    "    param.requires_grad = True\n",
    "  else:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ly5oVFOZFSmT"
   },
   "source": [
    "### 6.2 Fine-Tuning Optimizer & Callbacks\n",
    "\n",
    "We define a new optimizer and learning rate scheduler for the fine-tuning phase. Only the parameters marked as trainable (i.e., from `denseblock4` and `norm5`) are updated during this phase.\n",
    "\n",
    "An `EarlyStopping` callback is also set up to prevent overfitting by halting training when the validation loss no longer improves.\n",
    "\n",
    "> **Note**: We print the active learning rate after optimizer setup to verify that the new learning rate is properly configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1751205519124,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "-OesUzVy9ph9",
    "outputId": "07f6a839-9cf8-4f9a-cbe5-b4a31060f701"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer for fine-tuning (only trainable parameters)\n",
    "ft_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# Print current learning rate (for verification)\n",
    "current_lr = ft_optimizer.param_groups[0]['lr']\n",
    "print(f\"Active learning rate: {current_lr}\")\n",
    "\n",
    "# Define scheduler for fine-tuning\n",
    "scheduler_ft = ReduceLROnPlateau(ft_optimizer, mode='min', patience=2, factor=0.1, verbose=True)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V11csMjd_We8"
   },
   "source": [
    "## 7. Fine-Tune Backbone (Training Loop)\n",
    "\n",
    "In this section, we perform **fine-tuning** by training the previously unfrozen layers (`denseblock4` and `norm5`) along with the classifier head. Unlike the warm-up phase, this step allows the model to adjust higher-level convolutional features to the specific patterns present in brain MRI images.\n",
    "\n",
    "The training loop here follows the same structure as the warm-up phase (Section 5), with updated optimizer and scheduler settings defined in Section 6.2. We continue to monitor validation loss and apply **early stopping** to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 130640,
     "status": "ok",
     "timestamp": 1751205649762,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "bKN4k86p_W1b",
    "outputId": "e6bba1bb-7dec-4f0b-e46a-82018bbcd865"
   },
   "outputs": [],
   "source": [
    "# Save initial model weights and set best validation loss to infinity\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  print(f\"-\" * 50)\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "  print(f\"-\" * 50)\n",
    "\n",
    "  # --- Train Phases ---\n",
    "  model.train()\n",
    "  train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "    images, labels = images.to(device), labels.to(device) # add images, labels ke device (gpu)\n",
    "\n",
    "    ft_optimizer.zero_grad() # reset gradient before backward pass to prevent accumulation\n",
    "    outputs = model(images)\n",
    "    loss = crieterion(outputs, labels)\n",
    "    loss.backward() # calculate the gradient of the loss\n",
    "    ft_optimizer.step() # update weight based on gradient\n",
    "\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs, dim=1) # take class prediction (argmax) from model output\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "  avg_train_loss = train_loss / total\n",
    "  train_acc = correct / total\n",
    "\n",
    "  # --- Validation Phases ---\n",
    "  model.eval() # enter eval mode: dropout, batchnorm will be deactive\n",
    "  val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  with torch.no_grad(): # Disable gradient calculations to make interfaces faster & more efficient\n",
    "    for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = crieterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item() * images.size(0)\n",
    "      _, predicted = torch.max(outputs, dim=1)\n",
    "      correct += (predicted == labels).sum().item()\n",
    "      total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / total\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    scheduler_ft.step(avg_val_loss)\n",
    "    early_stopping(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "      best_val_loss = avg_val_loss\n",
    "      best_model_wts = copy.deepcopy(model.state_dict())\n",
    "      torch.save(model.state_dict(), \"best_model_fineTuning.pth\")\n",
    "      print(f\"[INFO]: Best model FineTuning Updated\")\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "      print(f\"[INFO]: Training Stopped by early stopping\")\n",
    "      break\n",
    "\n",
    "# Load best model weights after training\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(f\"[INFO]: Best model from FineTuning Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llUVWny3_W9h"
   },
   "source": [
    "## 8. Save Final Model\n",
    "\n",
    "After fine-tuning, the best-performing model (based on validation loss) is saved using `torch.save()`. This ensures that the most generalizable version of the model is preserved for deployment or further evaluation.\n",
    "\n",
    "For privacy and reproducibility, the model is uploaded to Hugging Face Hub instead of being stored in a local path. The download link or model reference will be provided in the project source files.\n",
    "\n",
    "**Model location**: Refer to the model card or config file in the `src/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20737,
     "status": "ok",
     "timestamp": 1751205810676,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "m1jmscMEP9Fs",
    "outputId": "75ed41f6-ddf7-42e3-9506-95c750dd962d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2L6PyJrTP9Nd"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/path/to/your/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook documents an early-stage exploration into **medical image classification** using deep learning.\n",
    "\n",
    "By applying **transfer learning** with **DenseNet121** to a binary brain tumor dataset, I gained practical experience in designing data pipelines, implementing image augmentations, and managing training workflows in **PyTorch**.\n",
    "\n",
    "The process offered valuable insights into **model behavior**, **class distribution handling**, and the importance of **reproducible experiments** — all within a manageable yet meaningful problem space.\n",
    "\n",
    "This project serves as a foundational step in my journey through **computer vision**, and sets the stage for more complex tasks, such as **multiclass classification**, **model interpretability**, and eventual **deployment** in real-world scenarios.\n",
    "\n",
    "> 💡 This notebook is part of a progressive deep learning portfolio. Each step builds toward stronger modeling capabilities and a deeper understanding of applied AI in medical contexts.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNPzbjFuPqaAIfhDpAZ9mXQ",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
