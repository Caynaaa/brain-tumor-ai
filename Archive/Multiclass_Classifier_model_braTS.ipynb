{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0M7D4cvWYgdq"
   },
   "source": [
    "# Brain Tumor Multiclass Classifier (2D MRI)\n",
    "\n",
    "This notebook presents a deep learning pipeline for classifying 2D brain MRI scans into four tumor categories: **Glioma**, **Meningioma**, **Pituitary**, and **No Tumor**.\n",
    "\n",
    "The model is built using **PyTorch** and leverages a pre-trained **DenseNet121** backbone with a custom classifier head. Training is performed in two phases: a warm-up stage where only the head is trained, followed by fine-tuning of selected high-level convolutional blocks.\n",
    "\n",
    "The dataset used was originally published on [Kaggle](#) and is re-hosted on the **Hugging Face Hub** to simplify access and integration.\n",
    "\n",
    "This project is part of a personal initiative to explore medical imaging with computer vision, with emphasis on **transfer learning**, **training strategy**, and **model generalization**.\n",
    "\n",
    "> **Disclaimer:** This project is for **educational and research purposes only**. It is *not* intended for medical or clinical use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAucEmcB-hBj"
   },
   "source": [
    "## 1. Setup & Dependencies\n",
    "\n",
    "This section installs and imports the required libraries for data handling, model development, training, and evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCguIW3vcX0B"
   },
   "source": [
    "### 1.1 Install Dependencies (Colab Only)\n",
    "\n",
    "If you're using Google Colab, install the required packages using the command below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9251,
     "status": "ok",
     "timestamp": 1751038008466,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "SFm6wtpN_UJ1",
    "outputId": "fbd46c5f-6fb2-483b-b7cc-a17744ad1db7"
   },
   "outputs": [],
   "source": [
    "# Install Hugging Face datasets library (for Colab users)\n",
    "!pip install -U datasets fsspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thNIGADudoyT"
   },
   "source": [
    "### 1.2 Import Libraries\n",
    "\n",
    "We import all necessary libraries including PyTorch, Albumentations, scikit-learn, and Hugging Face datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AE_EJl0P-rLi"
   },
   "outputs": [],
   "source": [
    "# PyTorch core modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Torchvision for model architectures and data utilities\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "\n",
    "# Albumentations for data augmentation\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Scikit-learn \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Standard libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Hugging Face datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCqmGOXU_XNX"
   },
   "source": [
    "## 2. Load and Prepare Raw Dataset\n",
    "\n",
    "We load a multiclass brain MRI dataset from the Hugging Face Hub using the `load_dataset` function. This dataset contains four tumor categories and was originally sourced from Kaggle. It is automatically cached for reuse.\n",
    "\n",
    "The loaded data will be split into training and validation sets using a **stratified sampling** strategy to ensure balanced class representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YICKK1FXg5Pi"
   },
   "source": [
    "### 2.1 Load Dataset from Hugging Face\n",
    "\n",
    "We load the dataset directly using the `datasets` library. The dataset contains labeled 2D brain MRI scans across four classes: **glioma**, **meningioma**, **pituitary**, and **no tumor**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483,
     "referenced_widgets": [
      "5bca0a0f1dd84b45801ef52834330b7e",
      "9b82995379b44bd7866e4d708044edee",
      "c8191815e7f34c63afbb49d7557fcbd7",
      "7c4c443276de4418847d6215906c30ad",
      "d459ab31e18c47c89a874329247ed823",
      "6a1b608646e54f04a88007bbf1b82f26",
      "118790a28d30417b84df0501c6e19130",
      "c1570630315646b5814373193c7b73b3",
      "10bd085faa8d4d359259cfa331d4a86c",
      "3b738faeee164e7f8d5f366fbfc0d39d",
      "87ffbb5a2c9d47c3b054a2cc4190def4",
      "b1c49a9299eb453a98acb0cd2e0712f1",
      "f492f1354c8848189601c027f8ad162f",
      "d47ca4a6120340ef99ad591b85f6e6a8",
      "ff5983eaf03e4fee93b48073d84b77e4",
      "702d271442ef4832a334c726e8c0a35b",
      "edad9c4b4503415a85f64551cfe40438",
      "ed168d751aad47ff8e2243448c7f89a2",
      "c47cd9586e9140149c5cc7316cde85d9",
      "203ffcb5c21240dcbdc32fc40c605cbf",
      "5bfef388076d47518d2d6f17fefd1d05",
      "84731dba966e4556b31ac32dcd69480e",
      "e959b3721d354ebd82931e3e9bd2b35e",
      "3c97320120f840d5aa6d9344bef0b2c8",
      "a50fab9bcb46460c9a0817b9999692c3",
      "7361bf6a8d6240f08804bca2a2658eb7",
      "357267ebbc724bb7aedd50a3afba76d1",
      "9e62d333d2e44590a99114302d9edea2",
      "999fccd1aaf7435491737ab184bb297d",
      "6e86b7aae1d342828a39fdd63756cf98",
      "0872c8c7747a40c9b22553b4973c66a7",
      "81691bbd97a84a14a72e0430c1430efd",
      "9b810016ba274cd6ad70c94ade55b87f",
      "6235cb6a74d042db83d4f67937b5a2fb",
      "4c8bac3455714be892ef4df86d2fe04f",
      "8ab4d94c67eb4f75b24d61c3326ba95a",
      "be3a2fe8e7e241b889ade12ebba02544",
      "56d5506d0aa445a08b453c8f72636354",
      "2744a22fe8394e9993e0323748729800",
      "96cf7ebe7d32402bae30143f5f326ed4",
      "0543822d1fed4ceba70c3b7e074a84be",
      "b3d41f21ca61471daeac6aaf9666d225",
      "78ccca2c3e5641149f2c9ad80e7cbc6b",
      "32e9dfa142b44dc69b9809012652c617",
      "46cb7a0ab3584de58b106f3b3f95d1e1",
      "519f4a99d9e046628bd28270d191fa75",
      "f048350fa6e04ca58d76f4b14b700198",
      "e50451c2ee7a44a5b504318b76682a4a",
      "c7771c36bfbe46a49f5fae38ae1bc9ae",
      "3d6bdff487a14dd892ebcfbba3d573b6",
      "a4b54d9c3b57447c9ee821c675ba12c6",
      "7528de23f652458f8a78b2fa3fa417a1",
      "7e71c836f9084a7fac55f20ec861285d",
      "3edce68979ea468788626b2c67f0773f",
      "655e09c4d0c3418fb8d6bb3a1b7704f8"
     ]
    },
    "executionInfo": {
     "elapsed": 11555,
     "status": "ok",
     "timestamp": 1751038192982,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "wwI6MhkZAYer",
    "outputId": "e32e9253-1c03-47f4-c729-c280db701d14"
   },
   "outputs": [],
   "source": [
    "# Load brain tumor dataset from Hugging Face (auto-cached locally)\n",
    "ds = load_dataset(\"Cayanaaa/BrainTumorDatasets\", name=\"multiclass\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTkvCE1rhHqB"
   },
   "source": [
    "### 2.2 View Class Label Mapping\n",
    "\n",
    "This command reveals the label names and their corresponding integer encodings used internally by the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1751038348736,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "DpP7a_gVAj7E",
    "outputId": "52bb5b83-3ed1-4f32-99cf-fe1343d3f312"
   },
   "outputs": [],
   "source": [
    "# Display class labels and their corresponding integer indices\n",
    "print(ds['train'].features['label'].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O08teEpGheUR"
   },
   "source": [
    "### 2.3 Extract Images and Labels from Dataset\n",
    "\n",
    "We extract the raw image and label pairs from the dataset for further processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlTyAt-oAv72"
   },
   "outputs": [],
   "source": [
    "# Extract image-label pairs from the training split\n",
    "train_data = ds['train']\n",
    "images = train_data['image']\n",
    "labels = train_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dM93C5nEhkqO"
   },
   "source": [
    "### 2.4 Stratified Train-Validation Split\n",
    "\n",
    "To ensure balanced class distribution across the training and validation sets, we perform a stratified split. This minimizes the risk of class imbalance during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbqnEKFKB2sj"
   },
   "outputs": [],
   "source": [
    "# Split data into training and validation sets while preserving class distribution\n",
    "train_imgs, val_imgs, train_labels, val_labels = train_test_split(images, labels,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  stratify=labels,\n",
    "                                                                  random_state=42\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y1kNch0KCY8j"
   },
   "source": [
    "## 3. Dataset Preparation\n",
    "\n",
    "In this section, we prepare the image dataset by applying preprocessing and augmentation techniques, defining a custom PyTorch `Dataset` class, and creating `DataLoaders` for both training and validation phases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5YglDwGi-KK"
   },
   "source": [
    "### 3.1 Define Transformation Pipelines\n",
    "\n",
    "We define image preprocessing and augmentation pipelines using **Albumentations** to improve generalization and performance.\n",
    "\n",
    "- The **training pipeline** includes resizing, flipping, distortion, noise, and normalization.\n",
    "- The **validation pipeline** includes only resizing and normalization to ensure consistent evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwTJNgErCfE8"
   },
   "outputs": [],
   "source": [
    "# Define preprocessing & augmentation for training set\n",
    "train_T = A.Compose([\n",
    "    A.Resize(224, 224), # Resize to model input size\n",
    "    A.HorizontalFlip(p=0.5), # Random horizontal flip\n",
    "    A.VerticalFlip(p=0.5),  # Random vertical flip\n",
    "    A.RandomBrightnessContrast(p=0.2),  # Slight brightness/contrast variation\n",
    "    A.GridDistortion(num_steps=5, distort_limit=0.03, p=0.2),  # Grid-based distortion\n",
    "    A.GaussNoise(p=0.1), # Add Gaussian noise\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], # Normalize using ImageNet stats\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2() # Convert to PyTorch tensor\n",
    "])\n",
    "\n",
    "# Define preprocessing for validation set (no augmentation)\n",
    "val_T = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKUmC4tyE-F8"
   },
   "source": [
    "### 3.2 Define Custom Dataset Class\n",
    "\n",
    "We define a custom PyTorch `Dataset` class to:\n",
    "\n",
    "- Apply the appropriate transformations.\n",
    "- Return each image and its label in tensor format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbbQ1rcrFnIi"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to load image-label pairs and apply transforms\n",
    "class LoadDataset(Dataset):\n",
    "  def __init__(self, images, labels, transform=None):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    img = self.images[idx]\n",
    "    img = img.convert('RGB') # Ensure image is in RGB format\n",
    "    img = np.array(img)\n",
    "\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    if self.transform:\n",
    "      img = self.transform(image=img)['image']\n",
    "\n",
    "    return img, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyg6DlYdG-Jd"
   },
   "source": [
    "### 3.3 Create Dataset & DataLoader\n",
    "\n",
    "We wrap the image-label pairs using our custom `Dataset` class, and prepare `DataLoaders` to efficiently feed data during training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khf8G_pFGoAz"
   },
   "outputs": [],
   "source": [
    "# Wrap image and label arrays into Dataset objects\n",
    "train_dataset = LoadDataset(train_imgs, train_labels, train_T)\n",
    "val_dataset = LoadDataset(val_imgs, val_labels, val_T)\n",
    "\n",
    "# Create DataLoaders for batching and shuffling\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) # shuffle for training\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False) # no shuffle for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs7GmSflHQud"
   },
   "source": [
    "## 4. Model, Optimizer, and Training Setup\n",
    "\n",
    "We adopt a **transfer learning** approach using a pre-trained **DenseNet121** model. To preserve the visual features learned from ImageNet, all convolutional layers are **frozen**, and we train **only the classifier head**. This initial setup focuses on **feature extraction**, before performing full fine-tuning in a later stage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0bOfE1Kmk7W"
   },
   "source": [
    "### 4.1 Load Pre-trained Model\n",
    "\n",
    "We load **DenseNet121** with ImageNet weights to leverage powerful low-level feature extraction learned from large-scale natural images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 588,
     "status": "ok",
     "timestamp": 1751040178940,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "Q6bNXa_KHUYX",
    "outputId": "f041ddb0-4ddb-4960-d139-a4031f9e8574"
   },
   "outputs": [],
   "source": [
    "# Load DenseNet121 model pre-trained on ImageNet\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freeze all layers in the feature extractor to retain pre-trained representations\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "# Replace the classifier head to match the number of output classes (4)\n",
    "model.classifier = nn.Linear(model.classifier.in_features, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oA5cwI9nILc9"
   },
   "source": [
    "### 4.2 Define Optimizer, Scheduler, and Device\n",
    "\n",
    "We use the Adam optimizer to update only the classifier head. A learning rate scheduler reduces the learning rate when validation performance plateaus. GPU is used if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1751041460529,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "36WMVD6FId46",
    "outputId": "561f2a9d-3d96-410a-bc23-51f98fad775d"
   },
   "outputs": [],
   "source": [
    "# Configure optimizer to update only the classifier head\n",
    "early_optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "\n",
    "# Set up learning rate scheduler to reduce LR if validation loss stops improving\n",
    "scheduler_early = ReduceLROnPlateau(early_optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Automatically use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y2-NlvF9sPvO"
   },
   "source": [
    "### 4.3 Define Weighted Loss Function\n",
    "\n",
    "To address class imbalance in the training data, we compute class weights and apply them to the cross-entropy loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgNVFBE2sOK6"
   },
   "outputs": [],
   "source": [
    "# Compute class weights to handle imbalance and reduce bias toward frequent classes\n",
    "class_weight = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float32).to(device)\n",
    "\n",
    "# Define weighted cross-entropy loss\n",
    "crieterion = nn.CrossEntropyLoss(weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rm2OueC5sk_Z"
   },
   "source": [
    "### 4.4 Define Early Stopping\n",
    "\n",
    "We implement a custom early stopping mechanism to terminate training when the validation loss no longer improves after a specified number of epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hy5H29qWNEZE"
   },
   "outputs": [],
   "source": [
    "# Custom early stopping class to monitor validation performance\n",
    "# Stops training if no improvement is observed over 'patience' epochs\n",
    "class EarlyStopping:\n",
    "    def __init__(self, monitor='val_loss', mode='min', patience=3, delta=0.0, verbose=True):\n",
    "         \"\"\"\n",
    "        Args:\n",
    "            monitor (str): Metric to monitor ('val_loss' or 'val_acc')\n",
    "            mode (str): 'min' → lower is better, 'max' → higher is better\n",
    "            patience (int): # of epochs with no improvement before stopping\n",
    "            delta (float): Minimum change to qualify as improvement\n",
    "            verbose (bool): Print status each epoch if True\n",
    "        \"\"\"\n",
    "        self.monitor = monitor\n",
    "        self.mode = mode\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.best_score = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "        # Set comparison function and initial best value\n",
    "        if self.mode == 'min':\n",
    "            self.monitor_op = lambda current, best: current < best - self.delta\n",
    "            self.best_score = np.inf\n",
    "        elif self.mode == 'max':\n",
    "            self.monitor_op = lambda current, best: current > best + self.delta\n",
    "            self.best_score = -np.inf\n",
    "        else:\n",
    "            raise ValueError(\"mode must be 'min' or 'max'\")\n",
    "\n",
    "    def __call__(self, current_score):\n",
    "        # Initialize best score\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] Initial best {self.monitor}: {self.best_score:.4f}\")\n",
    "        # Check for improvement\n",
    "        elif self.monitor_op(current_score, self.best_score):\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] Improved {self.monitor}: {self.best_score:.4f}\")\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f\"[EarlyStopping] No improvement in {self.monitor} for {self.counter}/{self.patience} epochs.\")\n",
    "            # Stop training if performance has not improved for 'patience' epochs\n",
    "            if self.counter >= self.patience:\n",
    "                if self.verbose:\n",
    "                    print(f\"[EarlyStopping] Stopping training. Best {self.monitor}: {self.best_score:.4f}\")\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BD7D91GNJCP"
   },
   "outputs": [],
   "source": [
    "# Create an EarlyStopping instance to monitor validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN0S_JmiNWb-"
   },
   "source": [
    "## 5. Train Classifier Head (Warm-up Phase)\n",
    "\n",
    "In this phase, we only train the classifier head (fully connected layers) while keeping the backbone frozen. This **warm-up strategy** helps the model gradually adapt to the domain-specific brain MRI data without modifying the general features learned from ImageNet.\n",
    "\n",
    "The goal is to allow the final layers to specialize on our dataset before unfreezing and fine-tuning the entire network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 887229,
     "status": "ok",
     "timestamp": 1751044031239,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "zJGO8gHmNbyT",
    "outputId": "51bc242e-fda2-4b95-9692-3654b5aec96d"
   },
   "outputs": [],
   "source": [
    "# Save initial model weights and set best validation loss to infinity\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_loss = np.inf\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "  print(\"-\" * 50)\n",
    "  print(f\"Epoch {epoch+1}/{num_epoch}\")\n",
    "  print(\"-\" * 50)\n",
    "\n",
    "  # --- training Phase ---\n",
    "  model.train()\n",
    "  train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    early_optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = crieterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    early_optimizer.step()\n",
    "\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "  avg_train_loss = train_loss / total\n",
    "  train_acc = correct / total\n",
    "\n",
    "  # --- Validation Phase ---\n",
    "  model.eval()\n",
    "  val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = crieterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "  avg_val_loss = val_loss / total\n",
    "  val_acc = correct / total\n",
    "\n",
    "  print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}\")\n",
    "  print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}\")\n",
    "\n",
    "  # Step the learning rate scheduler and update early stopping\n",
    "  scheduler_early.step(avg_val_loss)\n",
    "  early_stopping(avg_val_loss)\n",
    "\n",
    "  # Save model weights if validation loss improves\n",
    "  if avg_val_loss < best_val_loss:\n",
    "    best_val_loss = avg_val_loss\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    torch.save(model.state_dict(), 'mct_best_model.pth')\n",
    "    print(f\"[INFO]: Best model updated\")\n",
    "\n",
    "  # Stop training if early stopping is triggered\n",
    "  if early_stopping.early_stop:\n",
    "    print(f\"[INFO]: Training Stopped by EarlyStopping\")\n",
    "    break\n",
    "\n",
    "# Load best model weights after training\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"[INFO]: Best Model Loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EJCKrMMSSrKy"
   },
   "source": [
    "## 6. Fine-Tuning Setup\n",
    "\n",
    "In this phase, we fine-tune the deeper parts of the model to better adapt to the brain tumor classification task. Instead of unfreezing the entire backbone, we selectively unfreeze the final convolutional block and normalization layer to balance adaptability and generalization.\n",
    "\n",
    "Fine-tuning allows the model to refine high-level features learned from ImageNet in a domain-specific context.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gU8MqIo9xNgM"
   },
   "source": [
    "### 6.1 Unfreeze Selected Layers\n",
    "\n",
    "Here, we unfreeze the `denseblock4` and `norm5` layers of the backbone while keeping all earlier layers frozen. This selective unfreezing helps avoid overfitting and reduces the risk of catastrophic forgetting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dI3-HEjXX0F"
   },
   "outputs": [],
   "source": [
    "# Only unfreeze the last DenseBlock and final batch norm layer (norm5)\n",
    "for name, param in model.named_parameters():\n",
    "  if 'denseblock4' in name or 'norm5' in name:\n",
    "    param.requires_grad = True\n",
    "  else:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDbRC7Z8X3PS"
   },
   "source": [
    "### 6.2 Fine-Tuning Optimizer & Callbacks\n",
    "\n",
    "We define a new optimizer and learning rate scheduler for the fine-tuning phase. Only the parameters marked as trainable (i.e., from `denseblock4` and `norm5`) are updated during this phase.\n",
    "\n",
    "An `EarlyStopping` callback is also set up to prevent overfitting by halting training when the validation loss no longer improves.\n",
    "\n",
    "> **Note**: We print the active learning rate after optimizer setup to verify that the new learning rate is properly configured.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x-Y0BVYYX9uD"
   },
   "outputs": [],
   "source": [
    "# Define optimizer for fine-tuning (only trainable parameters)\n",
    "ft_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "# Print current learning rate (for verification)\n",
    "current_lr = ft_optimizer.param_groups[0]['lr']\n",
    "print(f\"Active learning rate: {current_lr}\")\n",
    "\n",
    "# Define scheduler for fine-tuning\n",
    "scheduler_ft = ReduceLROnPlateau(ft_optimizer, mode='min', factor=0.1, patience=2)\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLS2wHFFYX0R"
   },
   "source": [
    "## 7. Fine-Tune Backbone (Training Loop)\n",
    "\n",
    "In this section, we perform **fine-tuning** by training the previously unfrozen layers (`denseblock4` and `norm5`) along with the classifier head. Unlike the warm-up phase, this step allows the model to adjust higher-level convolutional features to the specific patterns present in brain MRI images.\n",
    "\n",
    "The training loop here follows the same structure as the warm-up phase (Section 5), with updated optimizer and scheduler settings defined in Section 6.2. We continue to monitor validation loss and apply **early stopping** to prevent overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2002446,
     "status": "ok",
     "timestamp": 1751046784339,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "_z3B3IzdZBW8",
    "outputId": "3b99f1e1-a8ec-4be2-db10-2dfa848f10a8"
   },
   "outputs": [],
   "source": [
    "# Save initial model weights and set best validation loss to infinity\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_val_loss = np.inf\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "  print(f\"Epoch {epoch+1}/{num_epoch}\")\n",
    "  print(\"-\" * 50)\n",
    "\n",
    "  # --- training Phase ---\n",
    "  model.train()\n",
    "  train_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  for images, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "    ft_optimizer.zero_grad()\n",
    "    outputs = model(images)\n",
    "    loss = crieterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    ft_optimizer.step()\n",
    "\n",
    "    train_loss += loss.item() * images.size(0)\n",
    "    _, predicted = torch.max(outputs, dim=1)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "  avg_train_loss = train_loss / total\n",
    "  train_acc = correct / total\n",
    "\n",
    "  # --- Validation Phase ---\n",
    "  model.eval()\n",
    "  val_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Validation\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = crieterion(outputs, labels)\n",
    "\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "  avg_val_loss = val_loss / total\n",
    "  val_acc = correct / total\n",
    "\n",
    "  print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}\")\n",
    "  print(f\"Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc:.2f}\")\n",
    "\n",
    "  scheduler_ft.step(avg_val_loss)\n",
    "  early_stopping(avg_val_loss)\n",
    "\n",
    "  if avg_val_loss < best_val_loss:\n",
    "    best_val_loss = avg_val_loss\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    torch.save(model.state_dict(), 'mct_best_model.pth')\n",
    "    print(f\"[INFO]: Best model updated\")\n",
    "\n",
    "  if early_stopping.early_stop:\n",
    "    print(f\"[INFO]: Training Stopped by EarlyStopping\")\n",
    "    break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "print(\"[INFO]: Best Model Loaded\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbBr-YoGZvWv"
   },
   "source": [
    "## 8. Save Final Model\n",
    "\n",
    "After fine-tuning, the best-performing model (based on validation loss) is saved using `torch.save()`. This ensures that the most generalizable version of the model is preserved for deployment or further evaluation.\n",
    "\n",
    "For privacy and reproducibility, the model is uploaded to Hugging Face Hub instead of being stored in a local path. The download link or model reference will be provided in the project source files.\n",
    "\n",
    "**Model location**: Refer to the model card or config file in the `src/` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22840,
     "status": "ok",
     "timestamp": 1751048885607,
     "user": {
      "displayName": "M lutfi H Azzam",
      "userId": "10455614359958764409"
     },
     "user_tz": -420
    },
    "id": "PLBORnO1ogG5",
    "outputId": "d2c5fe99-600e-4b90-ca70-5ffa6aeee776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AZHjcso7pTqq"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/path/to/your/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03HKlS0epz17"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Expanding on the previous binary classification task, this notebook addresses a more nuanced challenge: **classifying brain MRI scans into four distinct tumor types**.\n",
    "\n",
    "While the underlying architecture and training strategy — including **transfer learning**, **data augmentation**, and **fine-tuning** — remain consistent with the earlier approach, the multiclass setting introduces additional complexity. These include more intricate **decision boundaries**, **inter-class imbalance**, and the need for more **robust evaluation**.\n",
    "\n",
    "Working through this project strengthened my understanding of **model scalability**, **multi-class loss handling**, and the practical limitations of generalization in medical image classification.\n",
    "\n",
    "This notebook reflects an important step in moving from foundational experimentation toward more sophisticated deep learning pipelines that are structured, reproducible, and scalable.\n",
    "\n",
    "> 💡 Together with the binary version, this project forms a continuous learning track that builds intuition, confidence, and capability in applying computer vision to real-world medical challenges.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNgQpKlZdkudTlroiMJV6wy",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
